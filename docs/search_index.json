[["index.html", "Making free books with RStudio’s RMarkdown &amp; Bookdown Chapter 1 Welcome 1.1 Learn all about Bookdown", " Making free books with RStudio’s RMarkdown &amp; Bookdown Julie Lowndes 2021-10-29 Chapter 1 Welcome hi It’s possible to create beautiful books for free using RStudio’s R Markdown and Yihui Xie’s bookdown and hosting them on Github. This is pretty new and incredibly cool. It is a really powerful way to communicate science using the same reproducible workflow you use for your analyses and collaborations. This tutorial borrows heavily from a lot of great tutorials and resources you should check out too – there are links throughout. It also parallels a previous tutorial Making free websites with RStudio’s R Markdown. The best way to learn is to follow along with your own laptop, but all are welcome. We’ll spend half the time with the tutorial and half the time for you to work on your own website and get help. If you bring your laptop please do this beforehand: install RStudio create a GitHub account (advice) set up your computer to talk to GitHub have RStudio linked directly (highly recommended) (instructions sections 8-14) or install the Desktop App or be familiar with git commands for the command line (tutorial) Examples: We have been using bookdown for the Ocean Health Index: ohi-science.org/data-science-training and Openscapes: openscapes.org/series. And R Markdown is much more than books and websites – here’s a one-minute video about R Markdown to get you excited. 1.1 Learn all about Bookdown The best way to learn more about bookdown is from Yihui Xie himself. You can read his book bookdown: Authoring Books and Technical Documents with R Markdown or watch his webinar introducing bookdown. "],["setup.html", "Chapter 2 Setting up Bookdown 2.1 Get “bookdown-tutorial” going on your local computer 2.2 Create your “awesome-book” GitHub repo 2.3 Turn “bookdown-tutorial” into “awesome-book” 2.4 Publish “awesome-book” 2.5 Moving forward", " Chapter 2 Setting up Bookdown The bookdown package and book is definitely the best way to get started. However, in practice I always find myself copying an existing, working book and modifying it instead of starting from scratch. So this tutorial is going to have you do that as well, using this book as the one you copy from. [more setup here] You will have to name your book’s repository. To differentiate your book’s repo name from this “bookdown-tutorial” repo, here we’ll call your book “awesome-book” but you should consistently name it what you want to name it. 2.1 Get “bookdown-tutorial” going on your local computer Go to https://github.com/jules32/bookdown-tutorial Click the green “clone or download” button and DOWNLOAD ZIP. Locally on your computer, unzip the folder, save it in a reasonable place Rename 2 things from “bookdown-tutorial” to “awesome-book.” You can do this in the finder/windows explorer: the folder itself (that you just unzipped) the .Rproj file Double-click the .Rproj file to launch RStudio Install packages and restart install.packages(\"bookdown\") install.packages(\"usethis\") Use the menu item Session &gt; Restart R Click on the Build tab in the top right pane Click on Build Book! Nice job! Now let’s make it yours, and connect it to GitHub. 2.2 Create your “awesome-book” GitHub repo Go to your GitHub account: github.com/username Click on Repositories, and the green button “New” to create a new repo Name this new repo “awesome-book” DO NOT initialize this repo with a README Click the green “create repository” button — this will take you to your new repo Click the tiny “clone or download” button near the top and COPY URL 2.3 Turn “bookdown-tutorial” into “awesome-book” The following is from Jenny Bryan’s Happy Git With R Go back to RStudio, to your “awesome-book” project In the Console, type usethis::use_git() and say Yes to the two prompts. This will restart R and give you a new Git tab in the upper right pane. Now, click on the Terminal tab next to the Console tab. Type git remote add origin &lt;paste your copied awesome-book github url here&gt; Type git push --set-upstream origin master 2.4 Publish “awesome-book” Last steps! Go back to github.com/username/“awesome-book” and refresh — our files should be there! But we want it to be a book published as https://username.github.io/awesome-book. Click Settings Scroll down to GitHub Settings Change the Source pulldown from “None” to “master branch /docs folder” It should say “Your site is ready to be published at https://username.github.io/awesome-book/” — click the link to see! Now, you’re set — you just need to write your book. 2.5 Moving forward As you write your .Rmd files, build the book and commit all files, including the docs/ folder, and your published book will be updated! "],["write.html", "Chapter 3 Writing in Bookdown", " Chapter 3 Writing in Bookdown Coming soon: Adding chapters Citations "],["basic-modelling-in-r.html", "Chapter 4 Basic modelling in R 4.1 Source, format, and plot data 4.2 Build a linear model 4.3 Analyse the model fit 4.4 Compare the predicted values with the actual values 4.5 Analyse the residuals 4.6 Linear regression with more than one variable 4.7 Fitting a polynomial regression", " Chapter 4 Basic modelling in R Creating a model is an essential part of forecasting and data analysis. I’ve put together a quick guide on my process for modelling data and checking model fit. The source data I use in this example is Melbourne’s weather record over a 12 month period. Daily temperature is based on macroscale weather and climate systems, however many observable measurements are correlated (i.e. hot days tend to have lots of sunshine). This makes using weather data great for model building. 4.1 Source, format, and plot data Before we get started, it is useful to have some packages up and running. #Useful packages for regression library(readr) library(readxl) library(ggplot2) library(dplyr) library(tidyverse) library(lubridate) library(modelr) library(cowplot) I’ve put together a csv file of weather observations in Melbourne in 2019. We begin our model by downloading the data from Github. #Input data url &lt;-&quot;https://raw.githubusercontent.com/charlescoverdale/predicttemperature/master/MEL_weather_2019.csv&quot; #We&#39;ll read this data in as a dataframe. The &#39;check.names&#39; function set to false means the funny units that the BOM use for column names won&#39;t affect the import. MEL_weather_2019 &lt;- read.csv(url, check.names = F) head(MEL_weather_2019) This data is relatively clean. One handy change to make is to make the date into a dynamic format (to easily switch between months, years, etc). #Add a proper date column MEL_weather_2019 &lt;- MEL_weather_2019 %&gt;% mutate(Date = make_date(Year, Month, Day)) We also notice that some of the column names have symbols in them. This can be tricky to work with, so let’s rename some columns into something more manageable. #Rename key df variables names(MEL_weather_2019)[4]&lt;- &quot;Solar_exposure&quot; names(MEL_weather_2019)[5]&lt;- &quot;Rainfall&quot; names(MEL_weather_2019)[6]&lt;- &quot;Max_temp&quot; head(MEL_weather_2019) We’re aiming to investigate if other weather variables can predict maximum temperatures. Solar exposure seems like a plausible place to start. We start by plotting the two variables to if there is a trend. #Plot the data MEL_temp_investigate &lt;- ggplot(MEL_weather_2019)+ geom_point(aes(y=Max_temp, x=Solar_exposure),col=&quot;grey&quot;)+ labs(title = &quot;Does solar exposure drive temperature in Melbourne?&quot;, caption = &quot;Data: Bureau of Meteorology 2020&quot;) + xlab(&quot;Solar exposure&quot;)+ ylab(&quot;Maximum temperature °C&quot;)+ scale_x_continuous(expand=c(0,0))+ theme_bw()+ theme(axis.text=element_text(size=10))+ theme(panel.grid.minor = element_blank()) MEL_temp_investigate Eyeballing the chart above, there seems to be a correlation between the two data sets. We’ll do one more quick plot to analyse the data. What is the distribution of temperature? ggplot(MEL_weather_2019, aes(x=Max_temp)) + geom_histogram(aes(y=..density..), colour=&quot;black&quot;, fill=&quot;lightblue&quot;)+ geom_density(alpha=.5, fill=&quot;grey&quot;,colour=&quot;darkblue&quot;)+ scale_x_continuous(breaks=c(5,10,15,20,25,30,35,40,45), expand=c(0,0))+ xlab(&quot;Temperature&quot;)+ ylab(&quot;Density&quot;)+ theme_bw()+ theme(axis.text=element_text(size=12))+ theme(panel.grid.minor = element_blank()) We can see here the data is right skewed (i.e. the mean will be greater than the median). We’ll need to keep this in mind. Let’s start building a model. 4.2 Build a linear model We start by looking whether a simple linear regression of solar exposure seems to be correlated with temperature. In R, we can use the linear model (lm) function. #Create a straight line estimate to fit the data temp_model &lt;- lm(Max_temp~Solar_exposure, data=MEL_weather_2019) 4.3 Analyse the model fit Let’s see how well solar exposure explains changes in temperature #Call a summary of the model summary(temp_model) The adjusted R squared value (one measure of model fit) is 0.3596. Furthermore the coefficient of our solar_exposure variable is statistically significant. 4.4 Compare the predicted values with the actual values We can use this lm function to predict values of temperature based on the level of solar exposure. We can then compare this to the actual temperature record, and see how well the model fits the data set. #Use this lm model to predict the values MEL_weather_2019 &lt;- MEL_weather_2019 %&gt;% mutate(predicted_temp=predict(temp_model,newdata=MEL_weather_2019)) #Calculate the prediction interval prediction_interval &lt;- predict(temp_model, newdata=MEL_weather_2019, interval = &quot;prediction&quot;) summary(prediction_interval) #Bind this prediction interval data back to the main set MEL_weather_2019 &lt;- cbind(MEL_weather_2019,prediction_interval) MEL_weather_2019 Model fit is easier to interpret graphically. Let’s plot the data with the model overlaid. #Plot a chart with data and model on it MEL_temp_predicted &lt;- ggplot(MEL_weather_2019)+ geom_point(aes(y=Max_temp, x=Solar_exposure), col=&quot;grey&quot;)+ geom_line(aes(y=predicted_temp,x=Solar_exposure), col=&quot;blue&quot;)+ geom_smooth(aes(y=Max_temp, x= Solar_exposure), method=lm)+ geom_line(aes(y=lwr,x=Solar_exposure), colour=&quot;red&quot;, linetype=&quot;dashed&quot;)+ geom_line(aes(y=upr,x=Solar_exposure), colour=&quot;red&quot;, linetype=&quot;dashed&quot;)+ labs(title = &quot;Does solar exposure drive temperature in Melbourne?&quot;, subtitle = &#39;Investigation using linear regression&#39;, caption = &quot;Data: Bureau of Meteorology 2020&quot;) + xlab(&quot;Solar exposure&quot;)+ ylab(&quot;Maximum temperature °C&quot;)+ scale_x_continuous(expand=c(0,0), breaks=c(0,5,10,15,20,25,30,35,40))+ theme_bw()+ theme(axis.text=element_text(size=10))+ theme(panel.grid.minor = element_blank()) MEL_temp_predicted This chart includes the model (blue line), confidence interval (grey band around the blue line), and a prediction interval (red dotted line). A prediction interval reflects the uncertainty around a single value (put simple: what is the reasonable upper and lower bound that this data point could be estimated at?). A confidence interval reflects the uncertainty around the mean prediction values (put simply: what is a reasonable upper and lower bound for the blue line at this x value?). Therefore, a prediction interval will be generally much wider than a confidence interval for the same value. 4.5 Analyse the residuals #Add the residuals to the series residuals_temp_predict &lt;- MEL_weather_2019 %&gt;% add_residuals(temp_model) Plot these residuals in a chart. residuals_temp_predict_chart &lt;- ggplot(data=residuals_temp_predict, aes(x=Solar_exposure, y=resid), col=&quot;grey&quot;)+ geom_ref_line(h=0,colour=&quot;blue&quot;, size=1)+ geom_point(col=&quot;grey&quot;)+ xlab(&quot;Solar exposure&quot;)+ ylab(&quot;Maximum temperature (°C)&quot;)+ theme_bw() + labs(title = &quot;Residual values from the linear model&quot;)+ theme(axis.text=element_text(size=12))+ scale_x_continuous(expand=c(0,0)) residuals_temp_predict_chart 4.6 Linear regression with more than one variable The linear model above is *okay*, but can we make it better? Let’s start by adding in some more variables into the linear regression. Rainfall data might assist our model in predicting temperature. Let’s add in that variable and analyse the results. temp_model_2 &lt;- lm(Max_temp ~ Solar_exposure + Rainfall, data=MEL_weather_2019) summary(temp_model_2) We can see that adding in rainfall made the model better (R squared value has increased to 0.4338). Next, we consider whether solar exposure and rainfall might be related to each other, as well as to temperature. For our third temperature model, we add an interaction variable between solar exposure and rainfall. temp_model_3 &lt;- lm(Max_temp ~ Solar_exposure + Rainfall + Solar_exposure:Rainfall, data=MEL_weather_2019) summary(temp_model_3) We now see this variable is significant, and improves the model slightly (seen by an adjusted R squared of 0.4529). 4.7 Fitting a polynomial regression When analysing the above data set, we see the issue is the sheer variance of temperatures associated with every other variable (it turns out weather forecasting is notoriously difficult). However we can expect that temperature follows a non-linear pattern throughout the year (in Australia it is hot in January-March, cold in June-August, then starts to warm up again). A linear model (e.g. a straight line) will be a very bad model for temperature — we need to introduce polynomials. For simplicity, we will introduce a new variable (Day_number) which is the day of the year (e.g. 1 January is #1, 31 December is #366). MEL_weather_2019 &lt;- MEL_weather_2019 %&gt;% mutate(Day_number=row_number()) head(MEL_weather_2019) Using the same dataset as above, let’s plot temperature in Melbourne in 2019. MEL_temp_chart &lt;- ggplot(MEL_weather_2019)+ geom_line(aes(x = Day_number, y = Max_temp)) + labs(title = &#39;Melbourne temperature profile&#39;, subtitle = &#39;Daily maximum temperature recorded in Melbourne in 2019&#39;, caption = &quot;Data: Bureau of Meteorology 2020&quot;) + xlab(&quot;Day of the year&quot;)+ ylab(&quot;Temperature&quot;)+ theme_bw() MEL_temp_chart We can see we’ll need a non-linear model to fit this data. Below we create a few different models. We start with a normal straight line model, then add an x² and x³ model. We then use these models and the ‘predict’ function to see what temperatures they forecast based on the input data. #Create a straight line estimate to fit the data poly1 &lt;- lm(Max_temp ~ poly(Day_number,1,raw=TRUE), data=MEL_weather_2019) summary(poly1) #Create a polynominal of order 2 to fit this data poly2 &lt;- lm(Max_temp ~ poly(Day_number,2,raw=TRUE), data=MEL_weather_2019) summary(poly2) #Create a polynominal of order 3 to fit this data poly3 &lt;- lm(Max_temp ~ poly(Day_number,3,raw=TRUE), data=MEL_weather_2019) summary(poly3) #Use these models to predict MEL_weather_2019 &lt;- MEL_weather_2019 %&gt;% mutate(poly1values=predict(poly1,newdata=MEL_weather_2019))%&gt;% mutate(poly2values=predict(poly2,newdata=MEL_weather_2019))%&gt;% mutate(poly3values=predict(poly3,newdata=MEL_weather_2019)) head(MEL_weather_2019) In the table above we can see the estimates for that data point from the various models. To see how well the models did graphically, we can plot the original data series with the polynominal models overlaid. #Plot a chart with all models on it MEL_weather_model_chart &lt;- ggplot(MEL_weather_2019)+ geom_line(aes(x=Day_number, y= Max_temp),col=&quot;grey&quot;)+ geom_line(aes(x=Day_number, y= poly1values),col=&quot;red&quot;) + geom_line(aes(x=Day_number, y= poly2values),col=&quot;green&quot;)+ geom_line(aes(x=Day_number, y= poly3values),col=&quot;blue&quot;)+ #Add text annotations geom_text(x=10,y=18,label=&quot;data series&quot;,col=&quot;grey&quot;,hjust=0)+ geom_text(x=10,y=16,label=&quot;linear&quot;,col=&quot;red&quot;,hjust=0)+ geom_text(x=10,y=13,label=parse(text=&quot;x^2&quot;),col=&quot;green&quot;,hjust=0)+ geom_text(x=10,y=10,label=parse(text=&quot;x^3&quot;),col=&quot;blue&quot;,hjust=0)+ labs(title = &quot;Estimating Melbourne&#39;s temperature&quot;, subtitle = &#39;Daily maximum temperature recorded in Melbourne in 2019&#39;, caption = &quot;Data: Bureau of Meteorology 2020&quot;) + xlim(0,366)+ ylim(10,45)+ scale_x_continuous(breaks= c(15,45,75,105,135,165,195,225,255,285,315,345), labels=c(&quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;, &quot;Oct&quot;, &quot;Nov&quot;, &quot;Dec&quot;), expand=c(0,0), limits=c(0,366)) + scale_y_continuous(breaks=c(10,15,20,25,30,35,40,45)) + xlab(&quot;&quot;)+ ylab(&quot;°C&quot;)+ theme_bw()+ theme(axis.text=element_text(size=12))+ theme(panel.grid.minor = element_blank()) MEL_weather_model_chart We can see in the chart above the polynomial models do much better at fitting the data. However, they are still highly variant. Just how variant are they? We can look at the residuals to find out. The residuals is the gap between the observed data point (i.e. the grey line) and our model. #Get the residuals for poly1 residuals_poly1 &lt;- MEL_weather_2019 %&gt;% add_residuals(poly1) residuals_poly1_chart &lt;- ggplot(data=residuals_poly1,aes(x=Day_number, y=resid))+ geom_ref_line(h=0,colour=&quot;red&quot;, size=1)+ geom_line()+ xlab(&quot;&quot;)+ ylab(&quot;°C&quot;)+ theme_bw()+ theme(axis.text=element_text(size=12))+ theme(axis.ticks.x=element_blank(), axis.text.x=element_blank()) residuals_poly1_chart #Get the residuals for poly2 residuals_poly2 &lt;- MEL_weather_2019%&gt;% add_residuals(poly2) residuals_poly2_chart &lt;- ggplot(data=residuals_poly2,aes(x=Day_number, y=resid))+ geom_ref_line(h=0,colour=&quot;green&quot;, size=1)+ geom_line()+ xlab(&quot;&quot;)+ ylab(&quot;°C&quot;)+ theme_bw()+ theme(axis.text=element_text(size=12))+ theme(axis.ticks.x=element_blank(), axis.text.x=element_blank()) residuals_poly2_chart #Get the residuals for poly3 residuals_poly3 &lt;- MEL_weather_2019 %&gt;% add_residuals(poly3) residuals_poly3_chart &lt;- ggplot(data=residuals_poly3,aes(x=Day_number, y=resid))+ geom_ref_line(h=0,colour=&quot;blue&quot;, size=1)+ geom_line()+ theme_bw()+ theme(axis.text=element_text(size=12))+ scale_x_continuous(breaks= c(15,45,75,105,135,165,195,225,255,285,315,345), labels=c(&quot;Jan&quot;, &quot;Feb&quot;, &quot;Mar&quot;, &quot;Apr&quot;, &quot;May&quot;, &quot;Jun&quot;, &quot;Jul&quot;, &quot;Aug&quot;, &quot;Sep&quot;, &quot;Oct&quot;, &quot;Nov&quot;, &quot;Dec&quot;), expand=c(0,0), limits=c(0,366))+ xlab(&quot;&quot;)+ ylab(&quot;°C&quot;) residuals_poly3_chart three_charts_single_page &lt;- plot_grid( residuals_poly1_chart, residuals_poly2_chart, residuals_poly3_chart, ncol=1,nrow=3,label_size=16) three_charts_single_page As we move from a linear, to a x², to a x³ model, we see the residuals decrease in volatility. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
